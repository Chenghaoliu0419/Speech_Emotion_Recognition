{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNl6A2NxWbjYKTfQcyFnYHt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GS9ZpwSW-X6W"},"outputs":[],"source":["from transformers import AutoModelForAudioClassification\n","import librosa, torch\n","\n","#load model\n","model = AutoModelForAudioClassification.from_pretrained(\"3loi/SER-Odyssey-Baseline-WavLM-Categorical-Attributes\", trust_remote_code=True)\n","\n","#get mean/std\n","mean = model.config.mean\n","std = model.config.std\n","\n","\n","#load an audio file\n","audio_path = \"/path/to/audio.wav\"\n","raw_wav, _ = librosa.load(audio_path, sr=model.config.sampling_rate)\n","\n","#normalize the audio by mean/std\n","norm_wav = (raw_wav - mean) / (std+0.000001)\n","\n","#generate the mask\n","mask = torch.ones(1, len(norm_wav))\n","\n","#batch it (add dim)\n","wavs = torch.tensor(norm_wav).unsqueeze(0)\n","\n","\n","#predict\n","with torch.no_grad():\n","    pred = model(wavs, mask)\n","\n","print(model.config.id2label)\n","print(pred)\n","#{0: 'Angry', 1: 'Sad', 2: 'Happy', 3: 'Surprise', 4: 'Fear', 5: 'Disgust', 6: 'Contempt', 7: 'Neutral'}\n","#tensor([[0.0015, 0.3651, 0.0593, 0.0315, 0.0600, 0.0125, 0.0319, 0.4382]])\n","\n","#convert logits to probability\n","probabilities = torch.nn.functional.softmax(pred, dim=1)\n","print(probabilities)\n","#[[0.0015, 0.3651, 0.0593, 0.0315, 0.0600, 0.0125, 0.0319, 0.4382]]\n"]}]}