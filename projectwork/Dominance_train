{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNylbChlPT0hYuPwkd/AfDl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YBN18FT4NkKr"},"outputs":[],"source":["pip install transformers datasets torchaudio librosa"]},{"cell_type":"code","source":["import torch\n","import librosa\n","import numpy as np\n","from datasets import load_dataset, DatasetDict\n","from transformers import AutoModelForAudioClassification, AutoFeatureExtractor, TrainingArguments, Trainer\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader\n","\n","# 加载预训练模型\n","model_name = \"3loi/SER-Odyssey-Baseline-WavLM-Dominance\"\n","model = AutoModelForAudioClassification.from_pretrained(model_name, trust_remote_code=True)\n","\n","# 获取模型的特征提取器，用于音频预处理\n","feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n","\n","# 设置采样率、均值和标准差\n","sampling_rate = model.config.sampling_rate\n","mean = model.config.mean\n","std = model.config.std\n","\n","# 加载 MSP-Podcast 数据集 (假设数据集已经以某种形式本地存在)\n","# 有 MSP-Podcast 数据集的音频文件和标签，将其加载成 Dataset 对象\n","def load_msp_podcast_dataset(audio_files, labels):\n","    # 这里假设 audio_files 是音频文件路径的列表，labels 是对应的支配度标签列表\n","    data = {'audio': audio_files, 'label': labels}\n","    return DatasetDict({\"train\": Dataset.from_dict(data)})\n","\n","# 假设我们有音频文件列表和对应的支配度标签\n","# audio_files = [...]  # 音频文件路径列表\n","# labels = [...]  # 支配度标签列表\n","\n","# 加载数据集\n","dataset = load_msp_podcast_dataset(audio_files, labels)\n","\n","# 数据集划分为训练集、验证集和测试集\n","train_testvalid = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n","test_valid = train_testvalid[\"test\"].train_test_split(test_size=0.5, seed=42)\n","\n","dataset = DatasetDict({\n","    \"train\": train_testvalid[\"train\"],\n","    \"validation\": test_valid[\"train\"],\n","    \"test\": test_valid[\"test\"]\n","})\n","\n","# 预处理函数：加载音频并进行标准化\n","def preprocess_function(examples):\n","    audio_path = examples[\"audio\"]\n","    raw_wav, _ = librosa.load(audio_path, sr=sampling_rate)\n","    norm_wav = (raw_wav - mean) / (std + 1e-6)\n","    inputs = feature_extractor(norm_wav, sampling_rate=sampling_rate, return_tensors=\"pt\")\n","    inputs[\"labels\"] = torch.tensor(examples[\"label\"], dtype=torch.float)\n","    return inputs\n","\n","# 应用预处理\n","dataset = dataset.map(preprocess_function)\n","\n","# 定义训练参数\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=5,\n","    weight_decay=0.01,\n","    logging_dir=\"./logs\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"mse\",\n",")\n","\n","# 自定义 MSE 评估指标\n","import evaluate\n","mse_metric = evaluate.load(\"mean_squared_error\")\n","\n","def compute_metrics(pred):\n","    preds = pred.predictions.squeeze()  # 去掉不必要的维度\n","    labels = pred.label_ids\n","    mse = mse_metric.compute(predictions=preds, references=labels)\n","    return {\"mse\": mse}\n","\n","# 使用 Trainer API 进行训练\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"validation\"],\n","    tokenizer=feature_extractor,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# 训练模型\n","trainer.train()\n","\n","# 评估模型\n","eval_results = trainer.evaluate(dataset[\"test\"])\n","print(f\"Test MSE: {eval_results['eval_mse']}\")\n","\n","# 保存模型\n","trainer.save_model(\"./trained_model\")\n"],"metadata":{"id":"pQMj2ISyNmgs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Use the trained model to make predictions on new audio data"],"metadata":{"id":"Qz_u73u2Nxyk"}},{"cell_type":"code","source":["def predict_dominance(audio_path, model, feature_extractor):\n","    # 加载和预处理音频\n","    raw_wav, _ = librosa.load(audio_path, sr=model.config.sampling_rate)\n","    norm_wav = (raw_wav - mean) / (std + 1e-6)\n","    inputs = feature_extractor(norm_wav, sampling_rate=sampling_rate, return_tensors=\"pt\")\n","\n","    # 进行预测\n","    with torch.no_grad():\n","        pred = model(inputs.input_values, attention_mask=torch.ones(1, inputs.input_values.shape[1]))\n","\n","    # 输出支配度分数\n","    return pred.logits.squeeze().item()\n","\n","# 示例预测\n","audio_path = \"/path/to/test_audio.wav\"\n","dominance_score = predict_dominance(audio_path, model, feature_extractor)\n","print(f\"Predicted Dominance Score: {dominance_score}\")\n"],"metadata":{"id":"BEqfBAVHNyI1"},"execution_count":null,"outputs":[]}]}